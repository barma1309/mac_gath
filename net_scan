import json
import os
import time
from datetime import datetime, timedelta
from scapy.all import ARP, Ether, srp
import requests
import logging
from concurrent.futures import ThreadPoolExecutor
import csv
from io import StringIO

# Настройка логирования
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('network_scan.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Путь к локальной базе OUI и параметры
OUI_FILE = "oui.json"
OUI_URL = "https://standards-oui.ieee.org/oui/oui.csv"
OUI_UPDATE_INTERVAL = 30 * 24 * 60 * 60  # 30 дней в секундах
MIN_OUI_ENTRIES = 10000  # Минимальное количество записей в базе OUI
API_RETRY_ATTEMPTS = 3  # Количество повторных попыток для API
API_DELAY = 0.5  # Задержка 0.5 секунды для соблюдения лимита 2 запроса/сек
RESULTS_FILE = "network_scan_results.json"
RETENTION_PERIOD = 60 * 24 * 60 * 60  # 60 дней в секундах


def load_oui_database():
    """Загружает локальную базу OUI или скачивает новую, если она устарела или повреждена."""
    if os.path.exists(OUI_FILE):
        file_mtime = os.path.getmtime(OUI_FILE)
        if time.time() - file_mtime < OUI_UPDATE_INTERVAL:
            try:
                with open(OUI_FILE, 'r', encoding='utf-8') as f:
                    oui_database = json.load(f)
                if len(oui_database) >= MIN_OUI_ENTRIES:
                    logger.info(f"Использование существующей базы OUI ({len(oui_database)} записей)")
                    return oui_database
                else:
                    logger.warning(f"Локальная база OUI содержит слишком мало записей ({len(oui_database)})")
            except Exception as e:
                logger.error(f"Ошибка загрузки локальной базы OUI: {e}")

    logger.info("Скачивание новой базы OUI...")
    try:
        response = requests.get(OUI_URL, timeout=10)
        response.raise_for_status()
        csv_data = StringIO(response.text)
        reader = csv.DictReader(csv_data)
        oui_database = {}
        for row in reader:
            oui = row['Assignment'].lower()
            oui_database[oui] = row['Organization Name']

        if len(oui_database) < MIN_OUI_ENTRIES:
            logger.error(f"Скачанная база OUI содержит слишком мало записей ({len(oui_database)})")
            return oui_database

        with open(OUI_FILE, 'w', encoding='utf-8') as f:
            json.dump(oui_database, f, ensure_ascii=False)
        logger.info(f"База OUI успешно обновлена и сохранена ({len(oui_database)} записей)")
        return oui_database
    except requests.RequestException as e:
        logger.error(f"Ошибка при скачивании базы OUI: {e}")
        return {}


def get_mac_vendor(mac_address, oui_database):
    """Определяет производителя по MAC-адресу, используя локальную базу или API."""
    oui = mac_address[:8].replace(':', '').lower()
    if oui in oui_database:
        logger.info(f"Производитель для MAC {mac_address} найден в локальной базе")
        return oui_database[oui]

    logger.info(f"Производитель для MAC {mac_address} не найден в локальной базе, запрос к API")
    for attempt in range(API_RETRY_ATTEMPTS):
        try:
            url = f"https://api.macvendors.com/{mac_address}"
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                time.sleep(API_DELAY)
                return response.text.strip()
            elif response.status_code == 429:
                logger.warning(f"Попытка {attempt + 1}: Превышен лимит запросов к macvendors.com для MAC {mac_address}")
                time.sleep(API_DELAY * (attempt + 1))
            else:
                logger.warning(
                    f"Попытка {attempt + 1}: Не удалось определить производителя для MAC {mac_address} через macvendors.com (код: {response.status_code})")
        except requests.RequestException as e:
            logger.error(f"Попытка {attempt + 1}: Ошибка запроса к macvendors.com для MAC {mac_address}: {e}")
        time.sleep(API_DELAY)

    try:
        url = f"https://api.maclookup.app/v2/macs/{mac_address}"
        response = requests.get(url, timeout=10)
        time.sleep(API_DELAY)
        if response.status_code == 200:
            data = response.json()
            return data.get('company', 'Unknown')
        logger.warning(f"Не удалось определить производителя для MAC {mac_address} через maclookup.app")
    except requests.RequestException as e:
        logger.error(f"Ошибка запроса к maclookup.app для MAC {mac_address}: {e}")

    return "Unknown"


def scan_network(ip_range):
    """Сканирует указанную подсеть с помощью широковещательного ARP-запроса."""
    logger.info(f"Сканирование подсети {ip_range} с помощью широковещательного ARP")
    devices = []
    arp = ARP(pdst=ip_range)
    ether = Ether(dst="ff:ff:ff:ff:ff:ff")
    packet = ether / arp
    try:
        result = srp(packet, timeout=2, verbose=False, multi=True)[0]
        for sent, received in result:
            devices.append({"ip": received.psrc, "mac": received.hwsrc, "subnet": ip_range})
            logger.info(f"Обнаружено устройство в {ip_range}: IP = {received.psrc}, MAC = {received.hwsrc}")
        logger.info(f"Сканирование подсети {ip_range} завершено. Найдено устройств: {len(devices)}")
    except Exception as e:
        logger.error(f"Ошибка при сканировании подсети {ip_range}: {e}")
    return devices


def process_vendor(device, oui_database):
    """Обрабатывает MAC-адрес устройства для определения производителя."""
    vendor = get_mac_vendor(device["mac"], oui_database)
    logger.info(f"MAC {device['mac']} -> Производитель: {vendor}")
    return {"mac": device["mac"], "vendor": vendor, "subnet": device["subnet"]}


def load_and_filter_results():
    """Загружает существующие результаты и удаляет записи старше 60 дней."""
    if os.path.exists(RESULTS_FILE):
        try:
            with open(RESULTS_FILE, 'r', encoding='utf-8') as f:
                results = json.load(f)
            if not isinstance(results, list):
                results = [results]
        except Exception as e:
            logger.error(f"Ошибка загрузки {RESULTS_FILE}: {e}")
            return []
    else:
        return []

    cutoff_time = datetime.now() - timedelta(seconds=RETENTION_PERIOD)
    filtered_results = [
        result for result in results
        if datetime.strptime(result['date'], "%Y-%m-%d %H:%M:%S") >= cutoff_time
    ]
    logger.info(f"Загружено {len(results)} записей, после фильтрации осталось {len(filtered_results)}")
    return filtered_results


def save_results(new_result):
    """Сохраняет новые результаты, добавляя их к отфильтрованным существующим."""
    results = load_and_filter_results()
    results.append(new_result)
    try:
        with open(RESULTS_FILE, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=4, ensure_ascii=False)
        logger.info("Результаты сохранены в network_scan_results.json")
    except Exception as e:
        logger.error(f"Ошибка при сохранении результатов: {e}")


def main():
    ip_range = "192.168.159.0/24"  # Указываем одну подсеть для сканирования

    oui_database = load_oui_database()
    devices = scan_network(ip_range)

    vendor_list = []
    with ThreadPoolExecutor(max_workers=2) as executor:
        vendor_list = list(executor.map(lambda d: process_vendor(d, oui_database), devices))

    vendor_count = {}
    subnet_vendors = {ip_range: {}}
    for entry in vendor_list:
        vendor = entry["vendor"]
        subnet = entry["subnet"]
        if vendor in vendor_count:
            vendor_count[vendor] += 1
        else:
            vendor_count[vendor] = 1
        if vendor in subnet_vendors[subnet]:
            subnet_vendors[subnet][vendor] += 1
        else:
            subnet_vendors[subnet][vendor] = 1

    new_result = {
        "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "vendors": [
            {"vendor": vendor, "count": count, "subnets": {
                subnet: subnet_vendors[subnet].get(vendor, 0) for subnet in [ip_range]
            }}
            for vendor, count in vendor_count.items()
        ]
    }

    save_results(new_result)


if __name__ == "__main__":
    main()
